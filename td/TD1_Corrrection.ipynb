{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "better-bachelor",
   "metadata": {},
   "source": [
    "In this practical session, we explore the use of the Laplacian operator on a surface, in order to solve heat diffusision, to perform shape matching, or even to compute geodesic distances !\n",
    "\n",
    "In a first step, we learn how to read and store triangulated surfaces (*meshes*), and how to build the discrete Laplace-Beltrami Operator. \n",
    "\n",
    "We then seek to use this operator in different practical scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-expression",
   "metadata": {},
   "source": [
    "# Setup envionment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-marketplace",
   "metadata": {},
   "source": [
    "Your Python environment should include `numpy`, `scipy`, `matplotlib` and `meshplot`. The latter can be installed from conda using:\n",
    "><code> conda install -c conda-forge meshplot\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-birthday",
   "metadata": {},
   "source": [
    "Please download [this zip file](https://www.lix.polytechnique.fr/Labo/Robin.Magnet/INF631/data.zip) and place all elements in the same folder as the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-protocol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "\n",
    "# If you did not put the elements of the zip file in the same folder as the the notebook add the next two lines\n",
    "# import sys\n",
    "# sys.path.append(\"PATH TO THE DIRECTORY WHERE YOU UNZIPED YOUR FILES\")\n",
    "import plot_utils as plu # Follow the above procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-nightmare",
   "metadata": {},
   "source": [
    "# 0. Reading and storing a mesh "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-illness",
   "metadata": {},
   "source": [
    "Unlike images, there are several ways to represent a discrete (triangulated) surface. In this session, we will stick to the most basic data structure which is made of:\n",
    "1. A list of vertex coordinates in $\\mathbb{R}^3$\n",
    "2. A list of triangles, each defined by 3 **ordered** vertex indices $i,j,k\\in\\mathbb{N}$. The order of the vertices define the direction of the normal.\n",
    "\n",
    "The `OFF` format, or **O**bject **F**ile **F**ormat, stores this information in a `.off` file, which we will use today. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-validation",
   "metadata": {},
   "source": [
    "Open the `bunny.off` file using a text editor, where the structure will look like :\n",
    "<blockquote>\n",
    "    <code>OFF\n",
    "34834 69451 0\n",
    "-0.0378297 0.12794 0.00447467\n",
    "-0.0447794 0.128887 0.00190497\n",
    "...\n",
    "-0.0400442 0.15362 -0.00816685\n",
    "3 20463 20462 19669 \n",
    "3 8845 8935 14299 \n",
    "...</code>\n",
    "</blockquote>\n",
    "\n",
    "As you may already understand, our `.off` file is presented as follows:\n",
    "<ol>\n",
    "    <li> First Line: <code>OFF</code> letters</li>\n",
    "    <li> Second Line:  <code>n m 0</code>, with $n$ the numbers of <b>vertices</b> and $m$ the number of <b>triangles</b></li>\n",
    "    <li> Next $n$ lines: <code>X Y Z</code> coordinates for each <b>vertex</b></li>\n",
    "    <li> Next $m$ lines: <code>3 i j k</code> indices of the vertices constituting each <b>face</b></li>\n",
    "</ol>\n",
    "\n",
    "In practice, the `OFF` file format can include some more information as you can see on [here](https://en.wikipedia.org/wiki/OFF_(file_format)) if you are interested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-stretch",
   "metadata": {},
   "source": [
    "### QUESTION 1\n",
    "<b> Write the function `read_off` which can read a basic `.off` file.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-occupation",
   "metadata": {},
   "source": [
    "**Tips** :\n",
    "<ol>\n",
    "    <li> You can use the <code>with</code> statement to efficiently process a file: <br>\n",
    "        <code>with open(filepath, 'r') as f:\n",
    "   # compute operation on file</code>\n",
    "    </li>\n",
    "    <li> <code>f.readline()</code> returns the next line</li>\n",
    "    <li> <code>text.strip().split()</code> removes breakline characters from <code>text</code> and splits with respect to spaces. Try it with <code>text=\"1 2 3\\n\"</code> to see what happens.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_off(filepath):\n",
    "    \"\"\"\n",
    "    Reads a simple .off file\n",
    "    \n",
    "    Input\n",
    "    --------------\n",
    "    filepath : str - path to the .off file\n",
    "    \n",
    "    Output\n",
    "    --------------\n",
    "    vertices : (n,3) array of vertex coordinates (float)\n",
    "    faces    : (m,3) array of faces defined by vertices index (integers)\n",
    "    \"\"\"\n",
    "    ## TODO\n",
    "    # READ THE OFF FILE with path \"filepath\" and return vertex and faces information\n",
    "    if len(filepath.split(\".\")) == 1:\n",
    "        filepath += \".off\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        all_lines = f.readlines()\n",
    "    \n",
    "    \n",
    "    n_vertices = int(all_lines[1].split(\" \")[0])\n",
    "    n_faces = int(all_lines[1].split(\" \")[1])\n",
    "\n",
    "    vertices_list = []\n",
    "    for i in range(n_vertices):\n",
    "        vertices_list.append([float(x) for x in all_lines[2+i].split(\" \")[:3]])\n",
    "\n",
    "    faces_list = []\n",
    "    for i in range(n_faces):\n",
    "        # Be careful to convert to int. Otherwise, you can use np.array(faces_list).astype(np.int32)\n",
    "        faces_list.append([int(x) for x in all_lines[2+i+n_vertices].split(\" \")[1:4]])\n",
    "    faces = np.array(faces_list)\n",
    "    vertices = np.array(vertices_list)\n",
    "    return vertices, faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-minority",
   "metadata": {},
   "source": [
    "As we will have to deal with several components regarding a single mesh, it might be good to create a specific class in which all information will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMesh:\n",
    "    def __init__(self, path):\n",
    "        \"\"\"\n",
    "        Initialize the mesh from a path\n",
    "        \"\"\"\n",
    "        self.vertices, self.faces = read_off(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-maryland",
   "metadata": {},
   "source": [
    "This way, if we define an instance of `MyMesh` as `mesh = MyMesh(filepath)`, the `__init__` function is automatically run with parameter `filepath` (ignore the `self` parameter).\n",
    "\n",
    "Then the mesh vertex coordinates can be accessed using `mesh.vertices`and its faces information with `mesh.faces`. These are the *properties* of our class.\n",
    "\n",
    "Let us load and visualize our bunny:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = MyMesh('bunny.off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "plu.plot(mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-corner",
   "metadata": {},
   "source": [
    "# 1. Discrete Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-artist",
   "metadata": {},
   "source": [
    "As seen in class, the Laplacian of a mesh is ubiquitous in geometry processing. The discrete laplacian is defined as\n",
    "$$\n",
    "L = A^{-1}W\n",
    "$$\n",
    "with $A$ the (diagonal) area matrix, and $W$ the cotangent weight matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-remedy",
   "metadata": {},
   "source": [
    "**Notes for Sparse Matrices**<br>\n",
    "As the Laplace-Operator is a differential operator, it only locally acts at a point with respect to a local neighborhood. When storing it in a $n\\times n$ matrix, this results in numerous zero entries, which are useless to keep in memory.\n",
    "\n",
    "For both speed and memory efficiency, we use sparse matrices to represent such operators, where only non-zero entries are stored. The most basic structure for a sparse matrix is the **COO**rdinate format, which consists in three lists $I,J,V$ which respectively store the line index, column index and value for each non-zero entry.\n",
    "\n",
    "For algebra manipulations (matrix vector multiplications, linear system, ...), other format such as **C**ompressed **S**parse **R**ow (CSR) provide a substential speedup compared to COO. You can read about the CSR and CSC format [here](https://en.wikipedia.org/wiki/Sparse_matrix).\n",
    "\n",
    "In the [`scipy.sparse`](https://docs.scipy.org/doc/scipy/reference/sparse.html) library, you can generate COO, CSR or CSC matrices from the $I,J,V$ format using for instance<br>\n",
    "> <code>scipy.sparse.csr_matrix((V, (I,J)), shape=(N,N))</code>\n",
    "\n",
    "Note that depending on your python version, you might now have access to the more recent `scipy.sparse.csr_array` functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-check",
   "metadata": {},
   "source": [
    "**Notes for numpy linear algebra**<br>\n",
    "A few tips for simpler reading of numpy\n",
    "<ol>\n",
    "    <li> <code>np.matmul(A, B)</code> and <code>A @ B</code> are the same </li>\n",
    "    <li><code>np.matmum(A, v)</code> and <code>A @ v</code> are the same</li>\n",
    "    <li><code>np.dot(u, v)</code> and <code>u @ v</code> are the same</li>\n",
    "    <li> <code>np.transpose(A)</code> and <code>A.T</code> are the same</li>\n",
    "</ol>\n",
    "\n",
    "This means <code>A @ B.T @ u</code> is the same as <code>np.matmul(A, np.matmul(np.transpose(B), u))</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-program",
   "metadata": {},
   "source": [
    "## Question 2 \n",
    "<b> Fill the functions <code>compute_faces_areas</code> and <code>area_matrix</code> to respectively compute the area of each face and the vertex-wise area matrix $A$</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-defense",
   "metadata": {},
   "source": [
    "Recall the area matrix $A$ is a $n\\times n$ diagonal matrix where each entry provide the corresponding vertex area defined as:\n",
    "$$\n",
    "A_{ii} = \\frac{1}{3}\\sum_{f\\in\\mathcal{F}\\\\ i\\in f} \\text{Area}(f)\n",
    "$$\n",
    "\n",
    "**Tip**: There are multiple ways to compute the area of a triangle $ABC$, one of them being $\\frac{1}{2}\\|\\vec{AB}\\times \\vec{AC}\\|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_faces_areas(vertices, faces):\n",
    "    \"\"\"\n",
    "    Compute the area of each face\n",
    "    \n",
    "    Input\n",
    "    --------------\n",
    "    vertices : (n,3) - vertex coordinates\n",
    "    faces    : (m,3) - faces defined by vertex indices\n",
    "    \n",
    "    Output\n",
    "    --------------\n",
    "    faces_areas : (m,) - area of each face\n",
    "    \"\"\"\n",
    "    ## TODO\n",
    "    # Compute the area of each triangle of the mesh.\n",
    "    verts_faces = vertices[faces]\n",
    "    v_1 = verts_faces[:, 0] - verts_faces[:, 1]\n",
    "    v_2 = verts_faces[:, 0] - verts_faces[:, 2]\n",
    "    n = np.cross(v_1, v_2)\n",
    "    faces_areas = 0.5*np.linalg.norm(n, axis=-1)\n",
    "    return faces_areas\n",
    "\n",
    "def area_matrix(vertices, faces):\n",
    "    \"\"\"\n",
    "    Compute the diagonal area matrix\n",
    "    \n",
    "    Input\n",
    "    --------------\n",
    "    vertices : (n,3) - vertex coordinates\n",
    "    faces    : (m,3) - faces defined by vertex indices\n",
    "    \n",
    "    Output\n",
    "    --------------\n",
    "    A : (n,n) sparse matrix in DIAgonal format\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "    # Compute the area of each vertex in the mesh.\n",
    "    # Use the formula above.\n",
    "    \n",
    "    faces_areas = compute_faces_areas(vertices, faces)\n",
    "    vertex_areas = np.zeros(vertices.shape[0])\n",
    "    for idx, f in enumerate(faces):\n",
    "        vertex_areas[f[0]] += faces_areas[idx]/3\n",
    "        vertex_areas[f[1]] += faces_areas[idx]/3\n",
    "        vertex_areas[f[2]] += faces_areas[idx]/3\n",
    "    \n",
    "    \n",
    "    # Create a SPARSE diagonal matix from vertex areas\n",
    "    N = vertices.shape[0]\n",
    "    A = sparse.dia_matrix((vertex_areas, 0), shape=(N, N))\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-party",
   "metadata": {},
   "source": [
    "<b>Sanity Check : Verify that your total area remains the same whether you sum all face areas or the entries of the area matrix</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_areas = compute_faces_areas(mesh.vertices, mesh.faces)\n",
    "\n",
    "A = area_matrix(mesh.vertices, mesh.faces)\n",
    "print(A.diagonal().sum() == faces_areas.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-seeker",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-intention",
   "metadata": {},
   "source": [
    "Recall the stiffness matrix $W$ is a $n\\times n$ sparse matrix. There are multiple ways to compute each entry, one of them being:\n",
    "$$\n",
    "W_{ij} = \\begin{cases}\n",
    "\\sum_{k\\neq i} W_{ik} \\quad&\\text{if}\\quad i=j\\\\\n",
    "-\\frac{1}{2} \\left(\\cot(\\alpha_{ij}) + \\cot(\\beta_{ij})\\right)\\quad&\\text{if}\\quad ij\\in\\mathcal{E}\\\\\n",
    "0 \\quad&\\text{else}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $\\alpha_{ij}$ and $\\beta_{ij}$ are the angles opposite to the edge $ij$. Note that actually $\\beta_{ij}=\\alpha_{ji}$. With other notations you can visualize this face on the image below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-butler",
   "metadata": {},
   "source": [
    "![title](https://www.researchgate.net/publication/361577236/figure/fig3/AS:1182638081617922@1658974299594/An-illustration-for-the-cotangent-weights.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-forth",
   "metadata": {},
   "source": [
    "### Question 3.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-guatemala",
   "metadata": {},
   "source": [
    "<b> Fill the function <code>get_cotan_weights</code> to compute the cotangent weights for each face</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-connection",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T18:18:10.218170Z",
     "start_time": "2023-11-12T18:18:10.183275Z"
    }
   },
   "outputs": [],
   "source": [
    "def cotan_weights(vertices, faces):\n",
    "    \"\"\"\n",
    "    Compute cotangent weights for each face. Each vertex will carry the cotan of its angle.\n",
    "    \n",
    "    For a face [i, j, k], the output will be [alpha_{jk}, alpha_{ki}, alpha_{ij}].\n",
    "    \n",
    "    Input\n",
    "    ----------\n",
    "    vertices : (n,3) - The vertices of the mesh\n",
    "    faces : (m,3) The faces of the mesh\n",
    "    \n",
    "    Output\n",
    "    -------\n",
    "    cotan_weights : (m,3) The cotangent weights for each face\n",
    "    \"\"\"\n",
    "    ### TODO - Compute the cotangent weights\n",
    "    verts_faces = vertices[faces]\n",
    "    e_01 = verts_faces[:, 0] - verts_faces[:, 1]\n",
    "    norm_01 = np.sqrt((e_01* e_01).sum(axis=-1))\n",
    "    e_02 = verts_faces[:, 0] - verts_faces[:, 2]\n",
    "    norm_02 = np.sqrt((e_02 * e_02).sum(axis=-1))\n",
    "    e_12 = verts_faces[:, 1] - verts_faces[:, 2]\n",
    "    norm_12 = np.sqrt((e_12 * e_12).sum(axis=-1))\n",
    "    alpha_01 = np.arccos(np.abs((e_02 * e_12).sum(axis=-1))/(norm_02*norm_12))\n",
    "    alpha_02 = np.arccos(np.abs((e_01 * e_12).sum(axis=-1))/(norm_01*norm_12))\n",
    "    alpha_12 = np.arccos(np.abs((e_01 * e_02).sum(axis=-1))/(norm_01*norm_02))\n",
    "    # This can be done in parallel using numpy, or by looping over the faces\n",
    "    return np.concatenate((alpha_12[:, None], alpha_02[:, None], alpha_01[:, None]), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-fountain",
   "metadata": {},
   "source": [
    "### Question 3.2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-rwanda",
   "metadata": {},
   "source": [
    "<b> Fill the function <code>cotan_matrix</code> to compute the cotangent weight matrix $W$</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cotan(x):\n",
    "    ## Most of the time it's okay to use 1/np.tan, but remember that it doesn't work for x = pi/2\n",
    "    return np.cos(x)/np.sin(x)\n",
    "\n",
    "def cotan_matrix2(vertices, faces):\n",
    "    ## Very naive version : might crash on computer with less than 16GB of memory (for the bunny), and super slow\n",
    "    alphas = cotan_weights(vertices, faces)\n",
    "    n_v = vertices.shape[0]\n",
    "    W = np.zeros((n_v, n_v))\n",
    "    for idx_face, (i, j, k) in enumerate(faces):\n",
    "        for idx_tup, [idx_1, idx_2] in enumerate([(j, k), (k, i), (i, j)]):\n",
    "            W[idx_1, idx_2] += -0.5*cotan(alphas[idx_face][idx_tup])\n",
    "            W[idx_2, idx_1] += -0.5*cotan(alphas[idx_face][idx_tup])\n",
    "    for i in range(n_v):\n",
    "        W[i, i] -= W[i, :].sum()\n",
    "    return W\n",
    "\n",
    "def cotan_matrix_naive(vertices, faces):\n",
    "    alphas = cotan_weights(vertices, faces)\n",
    "    n_v = vertices.shape[0]\n",
    "    # In comment: naive version of building I,J,V, loop over faces, slow because \n",
    "    # calculation inside a python loop\n",
    "    I, J, V = [], [], []\n",
    "    for idx_face, (i, j, k) in enumerate(faces):\n",
    "        for idx_tup, [idx_1, idx_2] in enumerate([(j, k), (k, i), (i, j)]):\n",
    "            value = -0.5*cotan(alphas[idx_face][idx_tup])\n",
    "            I.append(idx_1)\n",
    "            J.append(idx_2)\n",
    "            V.append(value)\n",
    "\n",
    "            I.append(idx_2)\n",
    "            J.append(idx_1)\n",
    "            V.append(value)\n",
    "\n",
    "            I.append(idx_1)\n",
    "            J.append(idx_1)\n",
    "            V.append(-value)\n",
    "\n",
    "            I.append(idx_2)\n",
    "            J.append(idx_2)\n",
    "            V.append(-value)\n",
    "    \n",
    "    I_np = np.array(I)\n",
    "    J_np = np.array(J)\n",
    "    V_np = np.array(V)\n",
    "    W = sparse.csc_matrix((V_np, (I_np, J_np)), shape=(n_v, n_v))\n",
    "    return W\n",
    "\n",
    "def cotan_matrix(vertices, faces):\n",
    "    \"\"\"\n",
    "    Compute the stiffness matrix\n",
    "    \n",
    "    Input\n",
    "    --------------\n",
    "    vertices : (n,3) - vertex coordinates\n",
    "    faces    : (m,3) - faces defined by vertex indices\n",
    "    \n",
    "    Output\n",
    "    --------------\n",
    "    W : (n,n) sparse matrix in CSC format\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    # Compute the entries I,J,V of the stiffness matrix\n",
    "    # Note that the same pair (i,j) of indices can appear multiple times in I,J\n",
    "    # The corresponding values in V are then summed by scipy.\n",
    "    alphas = cotan_weights(vertices, faces)\n",
    "    n_v = vertices.shape[0]\n",
    "    # Here, use advantage of numpy arrays\n",
    "    list_I = []\n",
    "    list_J = []\n",
    "    list_V = []\n",
    "    for idx_tup, (idx_1, idx_2) in enumerate([(1, 2), (2, 0), (0, 1)]):\n",
    "        value = -0.5*cotan(alphas[:, idx_tup])\n",
    "        list_I += [faces[:, idx_1], faces[:, idx_2], faces[:, idx_1], faces[:, idx_2]]\n",
    "        list_J += [faces[:, idx_2], faces[:, idx_1], faces[:, idx_1], faces[:, idx_2]]\n",
    "        list_V += [value, value, -value, -value]\n",
    "    I = np.concatenate(list_I, axis=0)\n",
    "    J = np.concatenate(list_J, axis=0)\n",
    "    V = np.concatenate(list_V, axis=0)\n",
    "    W = sparse.csc_matrix((V, (I, J)), shape=(n_v, n_v))\n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-sound",
   "metadata": {},
   "source": [
    "**Sanity Check : Ensure all terms sum to 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = cotan_matrix(mesh.vertices, mesh.faces)\n",
    "np.isclose(np.sum(L), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking execution times \n",
    "import time \n",
    "lot_of_memory = False # Only put true if your computer has memory > 16GB.\n",
    "t1 = time.time()\n",
    "if lot_of_memory:\n",
    "    cotan_matrix2(mesh.vertices, mesh.faces)\n",
    "t2 = time.time()\n",
    "cotan_matrix_naive(mesh.vertices, mesh.faces)\n",
    "t3 = time.time()\n",
    "cotan_matrix(mesh.vertices, mesh.faces)\n",
    "t4 = time.time()\n",
    "if lot_of_memory:\n",
    "    print(\"Time for Super Naïve : {0:02f}s, Naïve : {1:02f}, All numpy : {2:02f}\".format(t2-t1, t3-t2, t4-t3))\n",
    "else:\n",
    "    print(\"Time for Naïve : {1:02f}, All numpy : {2:02f}\".format(t2-t1, t3-t2, t4-t3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-ownership",
   "metadata": {},
   "source": [
    "Let us now integrate this Laplacian into our mesh class (nothing to change here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMesh:\n",
    "    def __init__(self, path):\n",
    "        \"\"\"\n",
    "        Initialize the mesh from a path\n",
    "        \"\"\"\n",
    "        self.vertices, self.faces = read_off(path)\n",
    "        \n",
    "    def compute_laplacian(self):\n",
    "        self.A = area_matrix(self.vertices, self.faces)\n",
    "        self.W = cotan_matrix(self.vertices, self.faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-spain",
   "metadata": {},
   "source": [
    "The function `compute_laplacian` is called a *method* of the class `MyMesh`, and can be called as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = MyMesh('bunny.off')\n",
    "mesh.compute_laplacian()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-priority",
   "metadata": {},
   "source": [
    "The `self` parameter actually defined the instance of the class `MyMesh` on which the method is called.\n",
    "Equivalentely, one could run `MyMesh.compute_laplacian(mesh)` instead of `mesh.compute_laplacian()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-experience",
   "metadata": {},
   "source": [
    "# 2. Diffusion on Surface "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-bread",
   "metadata": {},
   "source": [
    "## 2.1 Exact Diffusion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-royalty",
   "metadata": {},
   "source": [
    "Perhaps, the most common use of the Laplace-Beltrami operator is to simulate heat diffusion on an arbitrary surface.\n",
    "\n",
    "Recall that the Heat Equation is defined as\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial t} = \\Delta u\n",
    "$$\n",
    "\n",
    "Given an initial function $u_0$, the values $u_t$ at time $t$ can be obtained by discretizing the equation using single backward Euler Step, which leads to \n",
    "$$\n",
    "\\left(I_d - t\\Delta \\right) u_t = u_0\n",
    "$$\n",
    "\n",
    "Note however that the mathematical laplacian $\\Delta$ is <b>negative semidefinite</b>, while our laplacian $L$ is <b>positive semidefinite</b>, and $L\\simeq -\\Delta$. \n",
    "\n",
    "Replacing $\\Delta$ by $-L$ and multiplying the left and right side of the equation by $A$, which removes the inverse $A^{-1}$, we obtain\n",
    "\n",
    "$$\n",
    "\\left(A + tW \\right) u_t = A u_0\n",
    "$$\n",
    "\n",
    "Therefore, given $u_0$, the value of $u$ at time $t$ can be obtained by solving this **sparse** linear system (as the matrix $A + tW$ we want to invert is sparse).\n",
    "\n",
    "While the system is made of $n$ equations,  where $n$ is the number of vertices which can grow very large, the fact it is **sparse** enables the use of significanly faster solver than for dense systems of the same size. Note that solving the system **does not** require to actually invert $A + tW$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-converter",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "<b> Fill the function <code>diffuse_full</code> to compute diffusion of an initial function $f$ for time $t$</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-gauge",
   "metadata": {},
   "source": [
    "**Tip**: Use [`sparse.linalg.spsolve`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.spsolve.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffuse_full(f, mesh, t):\n",
    "    \"\"\"\n",
    "    Diffuse a function f on a mesh for time t\n",
    "    \n",
    "    Input\n",
    "    --------------\n",
    "    f       : (n,) - function values\n",
    "    mesh    : MyMesh - mesh on which to diffuse\n",
    "    t       : float - time for which to diffuse\n",
    "    \n",
    "    Output\n",
    "    --------------\n",
    "    f_diffuse : (n,) values of f after diffusion\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    # Solve the Diffusion process using the formula above\n",
    "    left_matrix = mesh.A + t*mesh.W\n",
    "    right_term = f\n",
    "    f_diffuse = sparse.linalg.spsolve(left_matrix, right_term)\n",
    "    return f_diffuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-poetry",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "<b> See what happens when diffusing a dirac function</b>\n",
    "\n",
    "**Tip**:\n",
    "<ol>\n",
    "    <li> Plotting the dirac function centered on index <code>ind</code> can be done with <code>plu.plot(mesh, points=ind)</code> </li>\n",
    "    <li> Plotting the diffused function <code>f_diffuse</code> can be done with <code>plu.plot(mesh, f_diffuse, colormap='Reds')</code> </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "ind = 9\n",
    "dirac = np.zeros(mesh.vertices.shape[0])\n",
    "dirac[ind] = 1\n",
    "\n",
    "#plu.plot(mesh, points=ind)\n",
    "diff_dirac = diffuse_full(dirac, mesh, 0.1)\n",
    "plu.plot(mesh, diff_dirac, colormap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-sitting",
   "metadata": {},
   "source": [
    "## 2.2 Approximate Diffusion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-malawi",
   "metadata": {},
   "source": [
    "As seen in class, the spectrum of the Laplace-Beltrami operator provides a functional basis which generalizes the standard Fourier Analysis to all surfaces.\n",
    "\n",
    "As the Laplacian is only positive **semidefinite**, its spectrum is obtained by solving the **generalized** eigenvalue problem $W\\phi = \\lambda A \\phi$.\n",
    "\n",
    "This spectrum consists in eigenvalues - eigenfunctions pairs $\\left(\\lambda_j, \\phi_j\\right)_j$.\n",
    "\n",
    "In practice, we only compute the first $K$ eigenfunctions where $K$ lies in $[10,100]$. This defines an **orthogonal** basis (with respect to the standard inner product defined by $A$), which already provides good approximations of many functions.\n",
    "\n",
    "In practice, the spectrum is stored as follows:\n",
    "<ol>\n",
    "    <li>The eigenvalues $\\left(\\lambda_j\\right)_j$ are stored in a list and seen as a diagonal matrix $\\Lambda$</li>\n",
    "    <li>The eigenvectors $\\left(\\phi_j\\right)_j$ are stored as columns of matrix $\\Phi$</li>\n",
    "</ol>\n",
    "\n",
    "and proposes the following properties:\n",
    "<ul>\n",
    "    <li><b>Orthogonality</b> of the inner product defined by $A$: $\\Phi^\\top A \\Phi = I_K$. This is the discrete translation of $\\langle \\phi_i, \\phi_j\\rangle_{A} = \\delta_{ij}$, where $\\delta$ is here the Kronecker symbol</li>\n",
    "    <li><b>Eigendecomposition</b>: $L\\Phi = \\Phi \\Lambda$ (or $W\\Phi = A\\Phi \\Lambda$). This is the discrete translation of $L\\phi_i=\\lambda_i\\phi_i$</li>\n",
    "    <li>The <b>projection</b> $\\alpha\\in\\mathbb{R}^K$ of a function $f\\in\\mathbb{R}^n$ on the basis is: $\\alpha = \\Phi^\\top A f$. This is the translation of $\\alpha_i=\\langle\\phi_i, f\\rangle_A$</li>\n",
    "    <li>Coefficients $\\alpha\\in\\mathbb{R}^K$ in the basis define a function $f\\in\\mathbb{R}^n$ on the shape as: $\\Phi\\alpha = f$. This is the translation of $f=\\sum_{i=0}^K \\alpha_i\\phi_i$</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-reality",
   "metadata": {},
   "source": [
    "Let's add the eigendecomposition of the Laplacian to the mesh class as a new method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMesh:\n",
    "    def __init__(self, path):\n",
    "        \"\"\"\n",
    "        Initialize the mesh from a path\n",
    "        \"\"\"\n",
    "        self.vertices, self.faces = read_off(path)\n",
    "        \n",
    "    def compute_laplacian(self):\n",
    "        self.A = area_matrix(self.vertices, self.faces)\n",
    "        self.W = cotan_matrix(self.vertices, self.faces)\n",
    "        \n",
    "    def compute_eigendecomposition(self, K):\n",
    "        self.eigenvalues, self.eigenvectors = sparse.linalg.eigsh(self.W, M=self.A,\n",
    "                                                                  k=K, sigma=-0.01)\n",
    "        # The sigma parameter allows to stabilize the eigendecomposition\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = MyMesh(\"bunny.off\")\n",
    "mesh.compute_laplacian()\n",
    "mesh.compute_eigendecomposition(150)  ## This can take some time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-wedding",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "<ol>\n",
    "    <li><b> Visualize some eigenfunctios of the Laplacian.</b></li>\n",
    "    <li><b> Visualize the effect of projecting a dirac function on a basis of different size</b>. Use the above explanations to project</li>\n",
    "</ol>\n",
    "\n",
    "**Tip** To plot a general function, it is good to use a simple colormap like `\"coolwarm\"`: <code>plu.plot(mesh, function, colormap=\"coolwarm\")</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO Plot projected dirac\n",
    "k_dirac = 150\n",
    "proj = (dirac[:, None] * (mesh.A @mesh.eigenvectors[:, :k_dirac])).sum(axis=0)\n",
    "rec = ((mesh.eigenvectors[:, :k_dirac])*proj[None, :]).sum(axis=-1)\n",
    "plu.plot(mesh, rec, colormap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-corrections",
   "metadata": {},
   "source": [
    "Coming back to Diffusion, we wish to solve the Diffusion process using spectral analysis. Recall the discretized diffusion equation was\n",
    "$$\n",
    "\\left(A + tW \\right) u_t = A u_0\n",
    "$$\n",
    "\n",
    "If we consider $u_t$ to lie in a basis of size $K$ - that is $u_t =\\Phi\\alpha_t$, multiplying by $\\Phi^\\top$ on the left gives\n",
    "$$\n",
    "\\left(I_K + t\\Lambda \\right) \\alpha_t = \\Phi^\\top A u_0\n",
    "$$\n",
    "\n",
    "Since the leftmost term is diagonal, this means $u_t =\\Phi\\alpha_t$ with the element-wise value:\n",
    "$$\n",
    "(\\alpha_t)_j = \\frac{\\beta_j}{1+\\lambda_j}\n",
    "$$\n",
    "\n",
    "where $\\beta=\\Phi^\\top A u_0$ is actually the **projection** of $u_0$ in the basis.\n",
    "\n",
    "Note that <b>this only requires elementary matrix multiplications</b> and not solving a linear system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-cricket",
   "metadata": {},
   "source": [
    "**Note**: In practice we can have a better approximation by coming back to the original heat equation $\\frac{\\partial u_t}{\\partial t} = \\Delta u_t$.\n",
    "\n",
    "Using $u_t =\\Phi\\alpha_t$ and $\\Delta\\Phi=-\\Phi\\Lambda$, we can obtain $\\frac{\\partial \\alpha_t}{\\partial t} = -\\Lambda \\alpha_t$, with $\\Lambda$ being a diagonal matrix. We then obtain\n",
    "$$\n",
    "(\\alpha_t)_j = \\exp(-\\lambda_j t) \\beta_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-passing",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "<b> Fill the function <code>diffuse_spectral</code> which diffuses a function f for a time t</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffuse_spectral(f, mesh, t, k):\n",
    "    \"\"\"\n",
    "    Diffuse a function f on a mesh for time t\n",
    "    \n",
    "    Input\n",
    "    --------------\n",
    "    f       : (n,) - function values\n",
    "    mesh    : MyMesh - mesh on which to diffuse\n",
    "    t       : float - time for which to diffuse\n",
    "    k       : int - size of the basis to use for diffusion\n",
    "    \n",
    "    Output\n",
    "    --------------\n",
    "    f_diffuse : (n,) values of f after diffusion\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    # Solve the Diffusion process using spectral analysis.\n",
    "    # Use the formula above.\n",
    "    # Note that you should return the function u_t, NOT alpha_t !\n",
    "    beta = (f[:, None] * (mesh.A @ mesh.eigenvectors[:, :k])).sum(axis=0)\n",
    "    alpha = np.exp(-mesh.eigenvalues[:k]*t)*beta\n",
    "    f_diffuse = ((mesh.eigenvectors[:, :k])*alpha[None, :]).sum(axis=-1)\n",
    "    return f_diffuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-apache",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "<b>Compare the results of the diffusion using the exact and spectral approach on :</b>\n",
    "<ol>\n",
    "    <li> <b>a dirac function</b>.</li>\n",
    "    <li> <b> a function $\\Phi\\alpha$ with $\\alpha\\sim \\otimes^k\\mathcal{U}(0,1)$ </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-destruction",
   "metadata": {},
   "source": [
    "Note that similarly to standard Fourier analysis, a dirac function require the entire range of frequencies to be represented in the basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dirac function, the result is very different (because of low pass effect)\n",
    "k_diff = 100\n",
    "diff_dirac_spectral = diffuse_spectral(dirac, mesh, 0.01, k=k_diff)\n",
    "plu.plot(mesh, diff_dirac_spectral, colormap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now showing a random function on the mesh\n",
    "alpha = np.random.rand(k_diff)\n",
    "rec_alpha = ((mesh.eigenvectors[:, :k_diff])*alpha[None, :]).sum(axis=-1)\n",
    "plu.plot(mesh, rec_alpha, colormap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_full_alpha = diffuse_full(rec_alpha, mesh, 0.0001)\n",
    "plu.plot(mesh, diff_full_alpha, colormap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_spec_alpha = diffuse_spectral(rec_alpha, mesh, 0.0001, k_diff)\n",
    "plu.plot(mesh, diff_spec_alpha, colormap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(diff_full_alpha - diff_spec_alpha)/(np.linalg.norm(diff_full_alpha)*np.linalg.norm(diff_spec_alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-rating",
   "metadata": {},
   "source": [
    "# 3. The Heat Kernel Signature (Bonus, simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-tension",
   "metadata": {},
   "source": [
    "The [Heat Kernel Signature](http://www.lix.polytechnique.fr/~maks/papers/hks.pdf) (**HKS**) is a pointwise descriptor which provides local information invariant under isometry. In particular, this allows to compute correspondences between near-isometric surfaces.\n",
    "\n",
    "Given the spectrum $\\left(\\lambda_j, \\phi_j\\right)$ of the Laplacian of a shape, the HKS is defined as\n",
    "$$\n",
    "HKS(x,t) = C_t\\sum_j e^{-\\lambda_j t} \\phi_j(x)^2\n",
    "$$\n",
    "\n",
    "with $C_t^{-1} = \\sum_j  e^{-\\lambda_j t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-cemetery",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "<b>Fill the `compute_HKS` function to compute HKS descriptor for some time parameters $t$</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_HKS(mesh, n_times, k):\n",
    "    # Defines a list of time parameters at which to compute HKS\n",
    "    abs_ev = sorted(np.abs(mesh.eigenvalues[:k]))\n",
    "    t_list = np.geomspace(4*np.log(10)/abs_ev[-1], 4*np.log(10)/abs_ev[1], n_times)  # (n_times,)\n",
    "    X_t = np.exp(-mesh.eigenvalues[None, :k]*t_list[:, None])\n",
    "    C_t = 1./X_t.sum(axis=-1)\n",
    "    ## TODO COMPUTE HKS\n",
    "    HKS = C_t * (X_t[None, :] * (mesh.eigenvectors**2)[:, None, :k]).sum(axis=-1)\n",
    "    return HKS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-particle",
   "metadata": {},
   "source": [
    "HKS can later be used as a means to compute shape correspondence. Given two shapes $\\mathcal{X}$ and $\\mathcal{Y}$, we define the HKS distance between $x\\in\\mathcal{X}$ and $y\\in\\mathcal{Y}$ as\n",
    "$$\n",
    "d_{HKS}(x,y) = \\int_t |HKS_\\mathcal{X}(x,t) -  HKS_\\mathcal{Y}(y,t)|d\\log t\n",
    "$$\n",
    "\n",
    "The logarithmic sampling in `compute_HKS` naturally amounts for the $d\\log t$ integration, so two embeddings obtained with our function `compute_HKS` can simply be compared using the standard norm of the difference.\n",
    "\n",
    "Eventually, correspondences $T_{\\mathcal{Y}\\mathcal{X}}$ from $\\mathcal{Y}$ to $\\mathcal{X}$ can be obtained by setting\n",
    "$$\n",
    "T_{\\mathcal{Y}\\mathcal{X}}(y) = \\underset{y\\in\\mathcal{Y}}{\\text{argmin}}\\ d_{HKS}(x,y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-sample",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "<b>Use HKS to compute correspondences between two surfaces</b>\n",
    "\n",
    "**Tips**: \n",
    "<ol>\n",
    "    <li> $T_{\\mathcal{Y}\\mathcal{X}}$ is stored as a $n_\\mathcal{Y}$ dimensional array where the $i$-th entry gives the index of the image of $y_i$ in $\\mathcal{X}$ </li>\n",
    "    <li> Plot correspondences $T_{\\mathcal{Y}\\mathcal{X}}$ using <code>plu.plot_p2p(mesh1, mesh2, T_YX)</code></li>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "class KNNSearch(object):\n",
    "    DTYPE = np.float32\n",
    "    NJOBS = 4\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = np.asarray(data, dtype=self.DTYPE)\n",
    "        self.kdtree = cKDTree(self.data)\n",
    "\n",
    "    def query(self, kpts, k, return_dists=False):\n",
    "        kpts = np.asarray(kpts, dtype=self.DTYPE)\n",
    "        nndists, nnindices = self.kdtree.query(kpts, k=k, workers=self.NJOBS)\n",
    "        if return_dists:\n",
    "            return nnindices, nndists\n",
    "        else:\n",
    "            return nnindices\n",
    "\n",
    "    def query_ball(self, kpt, radius):\n",
    "        kpt = np.asarray(kpt, dtype=self.DTYPE)\n",
    "        assert kpt.ndim == 1\n",
    "        nnindices = self.kdtree.query_ball_point(kpt, radius, n_jobs=self.NJOBS)\n",
    "        return nnindices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh1 = MyMesh(\"hand1\")\n",
    "mesh2 = MyMesh(\"hand2\")\n",
    "\n",
    "mesh1.compute_laplacian()\n",
    "mesh1.compute_eigendecomposition(100)  ## This can take some time\n",
    "\n",
    "\n",
    "mesh2.compute_laplacian()\n",
    "mesh2.compute_eigendecomposition(100)  ## This can take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "hks1 = compute_HKS(mesh1, 128, 10)\n",
    "hks2 = compute_HKS(mesh2, 128, 10)\n",
    "print(hks1.shape)\n",
    "querier = KNNSearch(hks1)\n",
    "nn_indices = querier.query(hks2, 1)\n",
    "# dists = (hks1[:, None]**2).sum(axis=-1) + (hks2[None, :]**2).sum(axis=-1) - 2*np.inner(hks1, hks2)\n",
    "# nn_indices = np.argmin(dists, axis=0)\n",
    "plu.plot_p2p(mesh1, mesh2, nn_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-convergence",
   "metadata": {},
   "source": [
    "# 4. Heat Method for geodesic (BONUS) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-above",
   "metadata": {},
   "source": [
    "The [Heat method](https://www.cs.cmu.edu/~kmcrane/Projects/HeatMethod/paperCACM.pdf) uses the diffusion process of a dirac function to compute geodesic distances across a mesh. One advantage of this method is speed and a formulation independant from the specific triangulation of the mesh as long as differential operators are defined (**results are not though**).\n",
    "\n",
    "Given a point $x$, we start from a diract function $\\delta_x$ centered on $x$. The heat method is solved as follows:\n",
    "\n",
    "<ol>\n",
    "    <li> Integrate the heat equation with $u_0=\\delta_x$, that is solve $\\left(A + tW \\right) u_t = A \\delta_x$. This diffuses a lot heat to points close to $x$ and the value decreases as we for further away points. </li>\n",
    "    <li> Evaluate the vector field $X=-\\nabla u_t / \\|\\nabla u_t \\|$ which gives the (opposite) normalized direction of diffusion, hopefully going *geodesically* towards $x$ </li>\n",
    "    <li> Solve the Poisson Equation $\\Delta \\varphi = \\nabla\\cdot X$ to obtain the geodesic distance $\\varphi$ ensuring the distance to $x$ is $0$ by adding the necessary constant</li>\n",
    "</ol>\n",
    "\n",
    "The time of diffusion $t$ is usually set as $h^2$ with $h$ the average edge length of the mesh."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-peter",
   "metadata": {},
   "source": [
    "## Question 11 (Bonus)\n",
    "**Implement the heat method usng the gradient and divergence operator we provide**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_f(f, vertices, faces, normals):\n",
    "    \"\"\"\n",
    "    Compute the gradient of a function on a mesh\n",
    "\n",
    "    Parameters\n",
    "    --------------------------\n",
    "    f          : (n,) function value on each vertex\n",
    "    vertices   : (n,3) coordinates of vertices\n",
    "    faces      : (m,3) indices of vertices for each face\n",
    "    normals    : (m,3) normals coordinate for each face\n",
    "    face_area : (m,) - Optional, array of per-face area, for faster computation\n",
    "    use_sym    : bool - If true, uses the (slower but) symmetric expression\n",
    "                 of the gradient\n",
    "\n",
    "    Output\n",
    "    --------------------------\n",
    "    gradient : (m,3) gradient of f on the mesh\n",
    "    \"\"\"\n",
    "    v1 = vertices[faces[:,0]]  # (m,3)\n",
    "    v2 = vertices[faces[:,1]]  # (m,3)\n",
    "    v3 = vertices[faces[:,2]]  # (m,3)\n",
    "\n",
    "    f1 = f[faces[:,0]]  # (m,)\n",
    "    f2 = f[faces[:,1]]  # (m,)\n",
    "    f3 = f[faces[:,2]]  # (m,)\n",
    "\n",
    "    # Compute area for each face\n",
    "    face_areas = 0.5 * np.linalg.norm(np.cross(v2-v1,v3-v1),axis=1)  # (m)\n",
    "\n",
    "   \n",
    "\n",
    "    grad1 = np.cross(normals, v3-v2)/(2*face_areas[:,None])  # (m,3)\n",
    "    grad2 = np.cross(normals, v1-v3)/(2*face_areas[:,None])  # (m,3)\n",
    "    grad3 = np.cross(normals, v2-v1)/(2*face_areas[:,None])  # (m,3)\n",
    "\n",
    "    gradient = f1[:,None] * grad1 + f2[:,None] * grad2 + f3[:,None] * grad3\n",
    "\n",
    "    return gradient\n",
    "\n",
    "\n",
    "def div_f(f, vertices, faces, normals, vert_areas):\n",
    "    \"\"\"\n",
    "    Compute the divergence of a vector field on a mesh\n",
    "\n",
    "    Parameters\n",
    "    --------------------------\n",
    "    f          : (m,3) vector field on each face\n",
    "    vertices   : (n,3) coordinates of vertices\n",
    "    faces      : (m,3) indices of vertices for each face\n",
    "    normals    : (m,3) normals coordinate for each face\n",
    "    vert_area : (m,) - array of per-vertex area\n",
    "\n",
    "    Output\n",
    "    --------------------------\n",
    "    divergence : (n,) divergence of f on the mesh\n",
    "    \"\"\"\n",
    "    n_vertices = vertices.shape[0]\n",
    "\n",
    "    v1 = vertices[faces[:,0]]  # (m,3)\n",
    "    v2 = vertices[faces[:,1]]  # (m,3)\n",
    "    v3 = vertices[faces[:,2]]  # (m,3)\n",
    "\n",
    "    grad1 = np.einsum('ij,ij->i', np.cross(normals, v3 - v2) / 2, f)  # (m,)\n",
    "    grad2 = np.einsum('ij,ij->i', np.cross(normals, v1 - v3) / 2, f)  # (m,)\n",
    "    grad3 = np.einsum('ij,ij->i', np.cross(normals, v2 - v1) / 2, f)  # (m,)\n",
    "\n",
    "    I = np.concatenate([faces[:, 0], faces[:, 1], faces[:, 2]])  # (3*m)\n",
    "    J = np.zeros_like(I)\n",
    "    V = np.concatenate([grad1, grad2, grad3])\n",
    "\n",
    "    div_val = sparse.coo_matrix((V, (I, J)), shape=(n_vertices, 1)).todense()\n",
    "\n",
    "    return np.asarray(div_val).flatten() / vert_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_edge_length(mesh):\n",
    "    e1 = mesh.vertices[mesh.faces[:, 1]] - mesh.vertices[mesh.faces[:, 0]]\n",
    "    e2 = mesh.vertices[mesh.faces[:, 2]] - mesh.vertices[mesh.faces[:, 0]]\n",
    "    e3 =  mesh.vertices[mesh.faces[:, 2]] - mesh.vertices[mesh.faces[:, 1]]\n",
    "    l1 = np.linalg.norm(e1, axis=-1)\n",
    "    l2 = np.linalg.norm(e2, axis=-1)\n",
    "    l3 = np.linalg.norm(e3, axis=-1)\n",
    "    return (np.mean(l1) + np.mean(l2) + np.mean(l3))/3\n",
    "\n",
    "def face_normals(mesh):\n",
    "    e1 = mesh.vertices[mesh.faces[:, 1]] - mesh.vertices[mesh.faces[:, 0]]\n",
    "    e2 = mesh.vertices[mesh.faces[:, 2]] - mesh.vertices[mesh.faces[:, 0]]\n",
    "    cross = np.cross(e1, e2)\n",
    "    mesh_normals = cross/np.linalg.norm(cross, axis=-1, keepdims=True)\n",
    "    return mesh_normals\n",
    "\n",
    "def heat_distance(mesh, idx):\n",
    "    dirac = np.zeros(mesh.vertices.shape[0])\n",
    "    dirac[idx] = 1\n",
    "    # Computing diffusion of dirac \n",
    "    h = get_mean_edge_length(mesh)\n",
    "    diff_h = diffuse_full(dirac, mesh, h**2)\n",
    "    # Computing face normals\n",
    "    mesh_normals = face_normals(mesh)\n",
    "\n",
    "    # Heat method\n",
    "    grad_diff = grad_f(diff_h, mesh.vertices, mesh.faces, mesh_normals)\n",
    "    X = -grad_diff/np.linalg.norm(grad_diff, axis=-1, keepdims=True)\n",
    "    div_X = div_f(X, mesh.vertices, mesh.faces, mesh_normals, mesh.A.diagonal())\n",
    "    # Linear system (don't forget the mass matrix when discretizing!) \n",
    "    left = mesh.W \n",
    "    right = mesh.A @ div_X\n",
    "    sol = sparse.linalg.spsolve(left, right)\n",
    "    dists = sol - np.min(sol)\n",
    "    return dists, h\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "def line_plot(dists, h):\n",
    "    # Simple function to plot the level set of geod distances\n",
    "    plot_func = copy.deepcopy(dists)\n",
    "    eps = dists.max()/15\n",
    "    color_plot = plt.cm.coolwarm((plot_func-plot_func.min())/(plot_func.max()-plot_func.min()))\n",
    "    for i in range(15):\n",
    "        color_plot[np.logical_and(dists>i*eps-h/2, dists<i*eps+h/2), :] = 0\n",
    "    return color_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "geod_dists, h = heat_distance(mesh, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the resulting distance\n",
    "plu.plot(mesh, geod_dists, colormap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the level set, we're supposed to see \"circles\" of equidistant points to the chosen vertex\n",
    "plot_func = line_plot(geod_dists, h)\n",
    "plu.plot(mesh, cmap=plot_func[:, :3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
